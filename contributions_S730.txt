Contributions:

Edvin: 
* RandomForest and Gradient Boost + very basic tuning of them and brief description of them. Untuned kNN, LogReg, GaussianNB. 
* Discussion about apparent overfit of GB and RF.
* Discussed the performance difference when using raw in-data between the ensemble and non-ensemble methods.

Karl-Johan HÃ¤llgren:
* Everything to do with kNN tuning in the report, including the final kNN code and test submission.
* Main writer of scenario 1 & 2 in ethics section, as well as large parts of analysis

Mohammed Al-Jaff: 
* Exploraty data analyis, feature selection and dataset preprocessing. 
* support vector machine classification + tuning of the penalization hyperparameters. 
* Wrote introduction, and SVM parts + Data analysis parts of the report. Contributed to in discusion part about 0.8 ceiling, why could be the case and how this could be adressed by expanding features. 
* Brought Snacks :) 

Markus Johnson:
* Initial Python code, Github set up and test of all classier algoritms from the lecture slides:
    - Logistic regression
    - SVM
    - Lasso
    - Ridge regression
    - Random Forest 
    - Bootsting 
    . And more.
* Evaluate which classiers to investigate and test further
* Submitted first 3 predictions of songs liked to the site and continued to theak the models 
* Created inital draft for the rapport together with Mohammed Al-Jaff
* Fact checked rapport
* Included  and researched (hopefully) relevant references 